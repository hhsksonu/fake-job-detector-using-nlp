
# ğŸ” Fake Job Detector using NLP and SHAP Explaination

A Machine Learning and NLP-based project that detects fake job postings using real-world data. It leverages TF-IDF vectorization, XGBoost classifier, and model explainability tools like SHAP to identify and understand fraudulent job descriptions.

---
## ğŸ”‘ Key Highlights of the Project

Built an end-to-end Fake Job Detection system using Natural Language Processing  
Used TF-IDF vectorization to extract meaningful patterns from job descriptions  
Trained and optimized an XGBoost classifier to detect fake job postings  
Visualized important insights using word clouds, class imbalance plots, and confusion matrix  
Applied SHAP (SHapley Additive exPlanations) to interpret and explain model predictions  
Validated model fairness and transparency using SHAP force and waterfall plots  
Deployed a user-friendly Streamlit app for real-time fake job classification  

---
## ğŸ“¦ Features

- Paste any job posting and get real-time predictions  
- Confidence percentage displayed  
- SHAP explanation to visualize important features influencing the decision  
- Built with Streamlit, powered by XGBoost and TF-IDF 
---

## ğŸ“ Project Structure

```
fake-job-detector-using-nlp/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ app.ipynb
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ xgb_fake_job_model.pkl
â”‚   â””â”€â”€ README.md     â† âš ï¸ Start here if you're using the app
â”œâ”€â”€ data/             â† Dataset not stored here due to size
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                â† Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_model_training.ipynb     â† TF-IDF + XGBoost + Metrics
â”‚   â”œâ”€â”€ 03_explainability.ipynb     â† SHAP visualizations
â”œâ”€â”€ reports_screenshots/
â”‚   â”œâ”€â”€ wordcloud.png
â”‚   â”œâ”€â”€ Real-vs-Fake-Job.png
â”‚   â”œâ”€â”€ Null-value-heatmap.png
â”‚   â”œâ”€â”€ SHAP-force-plot.png
â”‚   â”œâ”€â”€ Waterfall-plot.png
â”‚   â”œâ”€â”€ Top-predictive-words.png
â”‚   â”œâ”€â”€ results.png
â”‚   â”œâ”€â”€ classification_report.csv
â”‚   â”œâ”€â”€ app-ss-1.png
â”‚   â”œâ”€â”€ app-ss-2.png
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Visual Results & Insights

Key insights from the model and data:

| ğŸ“Œ Description                          | ğŸ–¼ï¸ Image |
|----------------------------------------|----------|
| Null Values Heatmap                    | ![Null Heatmap](reports_screenshots/Null-value-heatmap.png) |
| WordCloud of Most Frequent Terms       | ![WordCloud](reports_screenshots/wordcloud.png) |
| Top Predictive Words (TF-IDF)          | ![Top Words](reports_screenshots/Top-predictive-words.png) |
| Real vs Fake Job Distribution          | ![Class Dist](reports_screenshots/Real-vs-Fake-Job.png) |
| Classification Results (Confusion + Metrics) | ![Results](reports_screenshots/results.png) |
| SHAP Force Plot (Explainability)       | ![SHAP Force](reports_screenshots/SHAP-force-plot.png) |
| SHAP Waterfall Plot (Single Prediction) | ![Waterfall Plot](reports_screenshots/Waterfall-plot.png) |

ğŸ“„ Detailed metrics can also be found in `classification_report.csv`.

---

## ğŸš€ Live Demo

ğŸ”— **[Click here to use the deployed app on Streamlit â†’](https://fake-job-detector-using-nlp-op3wr9fxrao2tul767qoax.streamlit.app/)**  
If the app appears blank, please refresh the page once.

---

## ğŸ“‚ Dataset Access

Due to the 25MB GitHub limit, the dataset is hosted externally:

ğŸ”— [Google Drive â€“ Dataset Folder](https://drive.google.com/drive/folders/1rFXS_Wndua__KcTPd4jMm_cicOmjSxy0?usp=sharing)

---

## âš™ï¸ How the App Works

Open the [`app/`](./app/) folder and read the included `README.md` for detailed setup instructions.

- If `app.py` doesn't run on your local machine, you can use `app.ipynb` instead.
- Just upload `app.ipynb` to Google Colab.
- Follow instructions there, and:
  - Set up `ngrok` for port forwarding.
  - Replace the dummy `your_token_here` with your actual ngrok token.

---

## ğŸ§  How I Built This Project

1. **Exploratory Data Analysis** â€“ Cleaned the data, explored nulls, plotted class imbalance.
2. **Model Training** â€“ TF-IDF vectorization + XGBoost classification. Tuned hyperparameters, measured metrics.
3. **Explainability** â€“ Used SHAP (SHapley Additive exPlanations) to interpret why certain jobs are predicted as fake.
4. **App Deployment** â€“ Built a simple Streamlit app for job posting classification.

Check out these notebooks:

```
â””â”€â”€ 01_eda.ipynb
â””â”€â”€ 02_model_training.ipynb
â””â”€â”€ 03_explainability.ipynb
```

---

## ğŸ“¦ Requirements

Install project dependencies from the main `requirements.txt`:

```bash
pip install -r requirements.txt
```

---

## ğŸ¤ Built By

ğŸ‘¨â€ğŸ’» **Sonu Kumar**

## ğŸ“¬ Contact Me

* ğŸ”— [LinkedIn](https://www.linkedin.com/in/hhsksonu)
* ğŸ”— [GitHub](https://github.com/hhsksonu)
